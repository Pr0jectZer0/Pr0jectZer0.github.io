# Vorlesung 15: Softwareprüfung

## Einleitung

## Software Qualität

## Qualitätsmaßnahmen

## Analysierende Verfahren

## Testende Verfahren

## Testarten im Software Entwicklungsprozess
### Testarten
<img src="images/VL15/testarten.png" width="70%" />

#### Unittest
* __Ziel:__ Aufdecken aller Abweichungen der Implementierung von der Spezifikation
 * Prüfen der Einzelfunktionen isoliert von den anderen Klassen des Systems

#### Integrationstest
* __Ziel:__ Aufdecken von Fehlern in Schnittstellen und im Zusammenspiel zwischen integrierten Klassen
 * Prüfen des Zusammenwirkens der Komponenten und Klassen

#### Systemtest
* __Ziel:__ Aufdeckung aller Abweichungen des Systemverhaltens in Bezug auf das in der Anforderungsdefinition spezifizierte Systemverhalten
 * Überprüfung..
  * ..der vollständigen Erfüllung der Benutzeranforderungen
  * ..der Korrektheit der Ergebnisse
  * ..der Robustheit gegen fehlerhafte Eingabedaten
  * ..von nichtfunktionalen Anforderungen

<img src="images/VL15/testebene.png" width="70%" />

#### Abnahmetest
* Akzeptanztest
* Neudeutsch: End-To-End-Test
* Test der Akzeptanz durch den Benutzer
* Auch Validierung nichtfunktionaler Anforderungen
* Test des Systems mit realen Daten unter realen Einsatzbedingungen
* Aufdecken aller Fehler, die auf Missverständnissen bei Absprachen zwischen Benutzer und Entwickler beruhen
* Test gegen Abnahmekriterien, die in der Anforderungsdefinition festgelegt wurden

<img src="images/VL15/testv.png" width="70%" />

## Weitere Testarten

### Regressionstest
* „Fertige“ Software wird geändert (neue Anforderungen oder Bugfixes)
* Gibt es Auswirkungen auf die alten Testergebnisse, wenn Änderungen vorgenommen worden sind?
* Benötigt automatisierte Wiederholbarkeit der Testfälle

<img src="images/VL15/regressionstest.png" width="70%" />

### Stresstest
* testen das Verhalten beim Überschreiten von definierten Grenzen

### Test des Speicherverhaltens (z.B. bei Verwendung von C/C++)
* welche Operationen fordern wie viel Speicherplatz an / geben ihn frei
* wo wird Speicher-Freigabe vergessen (memory leak = Speicherloch)
* wo wird auf bereits freigegebenen (oder nicht initialisierten) Speicherplatz zugegriffen
* wo wird Speicherplatz mehrfach freigegeben  und wo finden Zugriffe jenseits der Grenzen von Arrays statt

### GUI-Test
* Graphische Oberflächen sind Softwareschichten, die Logik enthalten und getestet werden müssen
* Daher gibt Capture & Replay-Werkzeuge: alle Mausbewegungen und Tastatureingaben werden aufgezeichnet und können dann zur Testwiederholung erneut abgespielt werden

### Penetrationstest
* z.B.: Hackerangriff simulieren

### Lasttest
* Ein Lasttest testet das System auf Zuverlässigkeit und das Einhalten der Spezifikation innerhalb des erlaubten Grenzbereichs
* Test der geforderten Performance
 * Transaktionsrate bzw. Antwortzeiten
* Skalierbarkeit
 * Anzahl Endbenutzer
 * Datenvolumen
* Zugriffskonflikte konkurrierender Benutzer

### Performancetest
* Untersuchung des Laufzeitverhaltens
* wie oft wird jede Methode aufgerufen
* welche Methode ruft wie oft welche andere Methode auf
* von welchen Methoden wird eine Methode wie oft aufgerufen
* wie viel Prozent der Gesamtlaufzeit wird mit der Ausführung einer bestimmten Methode verbracht
* Nutzen der ermittelten Daten
 * Operationen, die am meisten Laufzeit in Anspruch nehmen, optimieren
 * Tatsächliche Aufrufabhängigkeiten werden sofort sichtbar


## Ermittlung von Testfällen
### Ableitung von Testfällen bei Verwendung von UML
<img src="images/VL15/testUml.png" width="70%" />

### Testfallermittlung
* Auswahl der Testfälle ist eine zentrale Aufgabe des Testens
* Vollständiges Testen in der Regel unmöglich (stichprobenartig testen)
* __Ziel__: Mit möglichst wenig Testfällen möglichst viele Fehler finden

### Verfahren zur Testfallermittlung
<img src="images/VL15/testh.png" width="70%" />

* __Funktionsorientierter__ Test (Black-Box-Test):
    - Testfallauswahl aufgrund der Modulspezifikation Interne Struktur kann unbekannt sein prüft definierte Schnittstellen (Funktionalität)
    - _Datenbezogene Testfälle_:
        - Ausgehend von der Spezifikation des zu untersuchenden Objekts werden verschiedene Eingaben definiert, deren gewünschtes Resultat aus der Spezifikation abzuleiten ist
* __Strukturorientierter__ Test (White-Box-Test)
    - Testfallauswahl aufgrund der internen Struktur prüft die Details der Logik (Codereview)
    - Klassenspezifikation muss ebenfalls bekannt sein (erwartete Resultate)
    - _Ablaufbezogene Testfälle_:
        - Es wird die Struktur des zu untersuchenden Programms analysiert und versucht, möglichst alle Ablaufalternativen (if, while) durchzuspielen

## Funktionsorientierter Test
* Aufdeckung der Abweichung eines Testobjekts von seiner Spezifikation
* Auswahl der Testfälle ohne Kenntnis der inneren Struktur
* Überprüfung des Verhaltens des Testobjekts bei fehlerhaften Eingabedaten
* __Ziel__: Umfassende Prüfung der spezifizierten Funktionalität

__Verfahren zur Testfallermittlung__:
1. Error Guessing
2. Äquivalenzklassenbildung
3. Grenzwertanalyse

### Error Guessing
* Intuitive Auswahl des Testfälle aufgrund von Erfahrung
* Kein systematisches Verfahren
* Ergänzt die Methoden zur Testfallbestimmung

__Typische Fehler__:
* Nichtberücksichtigung von Sonderfällen (z. B. Division durch Null)
* Fehlende Behandlung von Grenzwerten
* Überschreitung von Feldgrenzen
* Endlosschleifen
* Nichtinitialisierung von Variablen
* Falsche logische Operationen (Negationen)

### Äquivalenzklassenbildung
* Gleichartige Eingabedaten werden zu Klassen zusammengefasst und aus jeder Klasse wird ein Repräsentant ausgewählt.
* Bestimmung von gültigen Äquivalenzklassen (Normalfall) sowie ungültigen Äquivalenzklassen (Sonderfall)
* Äquivalenzklassenbildung zerlegt die Menge der Eingaben in disjunkte Teilmengen
* Jeder Repräsentant einer Teilmenge hat das gleiche Verhalten bzgl. einer vorgegebenen Operation
* Beispiel: Restklassen (modulo x): werden zwei beliebige Repräsentanten aus Restklassen addiert, liegt das Ergebnis immer in derselben Restklasse
* Übertragungsidee auf Tests: Eingaben werden in Klassen unterteilt, die durch die Ausführung des zu testenden Systems zu „gleichartigen“ Ergebnissen führen

_Beispiel: Multiplikation zweier ganzer Zahlen:  „void mul(x, y)“_

__Mögliche Äquivalenzklassen__:
* X und Y sind positiv
* X ist positiv und Y ist negativ
* X ist negativ und Y ist positiv
* X und Y sind negativ

#### Regeln zur Bildung von Äquivalenzklassen
* man muss mögliche Eingaben kennen (aus Anforderungs-Spezifikation)
* für einfache Zahlenparameter: Intervall mit gültigen Werten
* Wenn explizit eine Menge von Werten vorgegeben ist: jeder Wert stellt eine Äquivalenzklasse dar

#### Beispiele für Äquivalenzklassen von Eingaben
* Erlaubte Eingabe: 1 <= Wert <= 99 (Wert sei ganzzahlig)
    - eine gültige Äquivalenzklasse: 1 <= Wert <= 99
    - zwei ungültige Äquivalenzklassen: Wert < 1, Wert > 99
* Erlaubte Eingabe in einer Textliste: für ein Auto können zwischen einem und sechs Besitzer eingetragen werden
    - eine gültige Äquivalenzklasse: ein bis sechs Besitzer
    - zwei ungültige Äquivalenzklassen: kein Besitzer, mehr als sechs Besitzer
* Erlaubte Eingabe: Instrumente Klavier, Geige, Orgel, Pauke
    - vier gültige Äquivalenzklassen: Klavier, Geige, Orgel, Pauke
    - eine ungültige Äquivalenzklasse: alles andere, z.B. Zimbeln

#### Beispiel Spezifikation:
* Einem Konstruktor zur Verwaltung von Studierenden wird ein Name, ein Geburtsjahr und ein Fachbereich übergeben.
* Einschränkungen:
    - Das Namensfeld darf nicht leer sein
    - Das Geburtsjahr muss zwischen 1900 und 2000 liegen
    - Es können nur die Fachbereiche aus einer Aufzählung (FBING, FBBWL und FBPOL) übergeben werden

| Eingabe          | gültige Äquivalenzklassen         |  ungültige Äquivalenzklassen   |
| :--------------- |:----------------------------------|:------------------------------ |
| __Name__         | _Ä1)_ nicht leer                  | _Ä2)_ leer                     |
| __Geburtsjahr__  | _Ä4)_ 1900< = Geburtsjahr <= 2000 | _Ä3)_ Geburtsjahr < 1900       |
|                  |                                   | _Ä5)_ Geburtsjahr > 2000       |
| __Fachbereich__  | _Ä6)_ FBING                       |                                |
|                  | _Ä7)_ FBBWL                       |                                |
|                  | _Ä8)_ FBPOL                       |                                |

#### Testfallerzeugung aus Äquivalenzklassen
Die Äquivalenzklassen sind eindeutig zu nummerieren. Für die Erzeugung von Testfällen aus den Äquivalenzklassen sind zwei Regeln zu beachten:
* gültige Äquivalenzklassen:
    - möglichst viele Klassen in einem Test kombinieren
* ungültige Äquivalenzklassen:
    - Auswahl eines (wichtig!) Testdatums aus einer ungültigen Äquivalenzklasse in Kombination mit Werten, die ausschließlich aus gültigen Äquivalenzklassen entnommen sind. Grund: für alle ungültigen Eingabewerte muss eine Fehlerbehandlung existieren

<img src="images/VL15/atable.png" width="70%" />

### Grenzwertanalyse
* Viele Software-Fehler sind auf Schwierigkeiten in Grenzbereichen der Äquivalenzklassen zurück zu führen (z.B. Extremwert nicht berücksichtigt, Array um ein Feld zu klein)
* Aus diesem Grund wird die Untersuchung von Äquivalenzklassen um die Untersuchung der Grenzen ergänzt
* Auswahl von Testfälle für solche Grenzfälle

_Beispiel: 1<=Wert<=99 (ganzzahlig)_
* _Äquivalenzklasse Wert<1:_
    - _obere Grenze Wert=0 (untere Grenze spielt hier keine Rolle)_
* _Äquivalenzklasse Wert>99:_
    - _untere Grenze Wert=100 (obere Grenze spielt keine Rolle)_
* _Äquivalenzklasse 1<=Wert<=99:_
    - _untere Grenze Wert=1 und obere Grenze Wert=99_

_Diese Grenzfallbetrachtung kann direkt in die Testfallerzeugung eingehen_

Testfälle nach einer Äquivalenzklassenanalyse und Grenzwertanalyse
(Testfallanzahl erhöht sich meist)

<img src="images/VL15/gtable.png" width="70%" />

#### Mögliche Übersetzung nach JUnit (Ausschnitt)
```java
import junit.framework.TestCase;

public class ImmatrikulationTest extends TestCase {
    ...

    public void test1(){
        try{
            new Immatrikulation("Meier", 1900, Bereich.FBING);
        }catch(ImmatrikulationsException e){
            fail("falsche Exception");
        }
    }

    public void test4(){
        try{
            new Immatrikulation("", 1988, Bereich.FBING);
            fail("fehlende Exception");
        }catch(ImmatrikulationsException e){
        }
    }

    ...
}

```

## Strukturorientierter Test

## Unittests
1. Die Anzahl der Code-Zeilen für Unittests übersteigt bei weitem die Anzahl der Zeilen des zu testenden Codes.
2. Ein Unittest testet genau eine Klasse.
3. Ein Test ist <strong>kein</strong> Unittest wenn:
  * Er kommuniziert mit einer Datenbank
  * Er kommuniziert mit einem Netzwerk
  * Er kann nicht gleichzeitig mit irgendeinem anderen Unittest ausgeführt werden
  * Es müssen spezille Dinge (wie Änderungen an Konfigurationsdateien) an der Umgebung für die Ausführung getan werden

### Test-Fixture
* Ein Testfall sieht in der Regel so aus, dass eine bestimmte Konfiguration von Objekten aufgebaut wird, gegen die der Test läuft.
* Diese Menge von Testobjekten wird auch als Test-Fixture bezeichnet.
* Damit fehlerhafte Testfälle nicht andere Testfälle beeinflussen können, wird die Test-Fixture für jeden Testfall neu initialisiert.
* In der Methode <strong>setUp</strong> werden Variablen initialisiert und mit der Methode <strong>tearDown</strong> werden wertvolle Testressourcen (z.B. Datenbank- oder Netzwerkverbindungen) wieder freigegeben.

### TestSuite
* Um eine Menge von Tests zusammen ausführen zu können, werden die Tests zu TestSuites zusammengefasst.
* Mit JUnit können beliebig viele Tests in einer TestSuite zusammengefasst werden.
* pro Package eine TestSuite-Klasse definieren.

## TDD (Test-driven delevopment)
<img src="images/VL15/TDD.png" width="100%"/>

### Zusammenspiel von Klassen testen
- Bis jetzt wurde nur eine Klasse betrachtet, die keine Assoziation zu anderen zu testenden Klassen hat
- Weil die Implementierung von andern Klassen noch nicht vorhanden sind, muss man die Implementierung "simulieren", sodass man die eigene Klasse testen kann
- Eine solche Klasse zur "Simulation" wird Test-Double genannnt.
- Liegt die Klasse vor, die man temporär durch den Test-Double prüfen wollte, können diese Tests mit einer realen Klasse wiederholt werden
- Test-Doubles dienen auch für die Implementierung von Klassen, die auf Ressourcen (z. B. Datenbanken) zugreifen, die nicht immer verfügbar sind
- Test-Doubles wurden früher per Hand programmiert. Heutzutage kann man diese per Software automatisch erzeugen lassen:
  * Beispiele: jMoch, http://jmock.org/, EasyMock, http://easymock.org/, Mockito, https://github.com/mockito/mockito
- Achtung:
  * Test-Doubles sind oft aufwändig in der Erstellung, müssen bei Änderungen am Code mit verändert werden und geben keine Garantie dafür, dass die Software keine Fehler enthält.

## Test Doubles
<img src="images/VL15/TestDoubles.png" width="100%"/>

- Mock: Dynamische und konfigurierbare Laufzeit-Implementierung eines Interfaces oder einer Klasse, für die Rückgabewerte von Methoden definiert werden.
- Stub: Fragmentartige Implementierung als Stellvertreter, genutzt zum Testen.
- Dummy: Ersatzklasse ohne Implementierung als Stellvertreter, um das Testen zu ermöglichen. Wird herumgereicht, aber nicht benutzt. (z.B. um eien Parameterliste einer Methode zu füllen). Muss existieren, aber eine "Interaktion" mit einem Dummy ist nicht angedacht.
- Dummies und Stubs werden erzeugt, um die Testumgebung "lauffähig" zu machen und nicht für die eigentliche "Verifikation" benutzt. Ein Dummy wird als "Wert" herumgereicht, während ein Stub Daten an die zu testende Klasse zurückgibt ("indirekte Inputs").
- Spy: Ein Mock, der die Aufrufe von Methoden etc. zählt
- Spies und Mocks werden benutzt, um die Korrektheit des Kommunikationsablauf zwischen zu testender Klasse und den daran beteiligten Klassen zu überprüfen ("indirekte Outputs").
- Fake: Funktionierende, einfach aufzusetzende, simplifizierte Implementierung mit "gehackter Funktionalität", also nicht verwendbar in Produktion(z.B. eine In-memory-Datenbank). Fakes werden in Integrationstests verwendet.
- Fakes spielen dieselbe Rolle wie Dummies oder Stubs. Sie werden erzeugt, um die Testumgebung lauffähig zu machen, aber nicht für die Verifikation benutzt.
- Test Doubles werden nicht für direkte Outputs der SUT benutzt.
