# Vorlesung 15: Softwareprüfung

## Einleitung

## Software Qualität

## Qualitätsmaßnahmen

## Analysierende Verfahren
### Entwurfsziele
- Niedrige Kopplung
	- Der Grad, zu dem die Klassen voneinander abhängig (Methodenaufrufe, Vererbung und Zugriff auf öffentliche Attribute) sind
	- Starke Kopplung entspricht starken Abhängigkeiten und erschwert Wiederverwendung und Wartbarkeit
- Hohe Kohäsion
	- Misst, wie stark verwandt oder fokussiert die Aufgaben eines Elementes (z.B. Klasse, Komponente, Paket) sind
	- Niedrige Kohäsion lässt darauf schließen, dass in einer Klasse mehrere Funktionalitäten implementiert wurden und erschwert das Verständnis und die Wiederverwendbarkeit

<img src="images/VL15/AnalVerfahren/Entwurfsziele.PNG" width=650>

Softwarequalität (z.B. Kohäsion und Kopplung) lässt sich auf zwei Arten messen?

### Quantitave und qualitative Aussagen über Softwarequalität
1. Qualitativ: 
	- mittels subjektiver Beurteilungsmethoden („gut“, „schlecht“) oder Review-Checklisten oder Codeinspektion
2. Quantitativ: Metrik 
	- Eine Softwaremetrik ist eine Funktion, die eine Software-Einheit in einen Zahlenwert abbildet, der als der Erfüllungsgrad  einer  Qualitätseigenschaft der Software-Einheit interpretiert wird.
	- Eine Metrik ist ein interpretiertes Maß, das automatisch ermittelt werden kann und ein Indiz für die Qualität eines Produktes ist
	- Metriken sollen nur als Indikatoren betrachtet werden, d.h. gewonnene Aussagen müssen nachgeprüft werden
	- Ergebnissen  nicht  blind  vertrauen,  sondern als Hilfsmittel  für  eigene Urteilsfindung interpretieren
	- Es existieren zwei Arten von Metriken
		1. Konventionelle Metriken
		2. OO-Metriken

<img src="images/VL15/AnalVerfahren/Metrik.PNG" width=650>

- Beispiel: SIZE (oder auch LOC=Lines of Code): Anzahl der Codezeilen
	- Leicht zu messen
	- Umfang variiert mit der Sprache, Programmierstil, etc.
	- Werden Kommentare dazu gezählt?

#### Zyklomatische Komplexität (McCabe)

- Codemaß, das die Komplexität von Kontrollflüssen in Methoden misst
- Quantitatives Maß für den erwarteten Testaufwand 
- Methoden mit einer hohen „Cyclomatic Complexity“ sind schwerer zu warten und zu testen
- Zyklomatische Komplexität gibt Obergrenze für die Testfallanzahl für den Zweigüberdeckungstest an
- Aber: „Lange“ Methoden sind nicht unbedingt komplex
- Folgt man McCabe, so sollen Methoden, für die z(G) > 10 gilt, einem Refactoring unterzogen werden

<img src="images/VL15/AnalVerfahren/ZyklomatischeKomplexität.PNG" width=650>

1. Man konstruiere die Kontrollflussgraphen
2. Man messe die strukturelle Komplexität
    Die zyklomatische Zahl z(G) eines Kontrollflussgraphen G ist:
				z(G) = e – n + 2 mit
		e = Anzahl der Kanten des Kontrollflussgraphen
		n = Anzahl der Knoten

<img src="images/VL15/AnalVerfahren/loops.PNG" width=650>

**Beispiele für die zyklomatische Komplexität**
<img src="images/VL15/AnalVerfahren/BeispielMcCabe.PNG" width=650>

					z(G) = e – n + 2

### Objektorientierte SW-Metriken
- In *objektorientierten Programmen* versagt die McCabe-Metrik, da die Kontrollflußkomplexit¨at der meisten Methoden gering ist (z (G) = 1).
- Metriken müssen deshalb das *Zusammenspiel der Klassen* betrachten – typischerweise anhand des (statischen) Objektmodells
- Werkzeuge für OO-Metriken, z.B.:
	- Checkstyle
	- JMetric
	- Eclipse plugin
		- http://metrics.sourceforge.net/
		- berechnet u. A. erweiterte MCCabe-Zahl und LCOM*

#### Beispiele für OO SW-Metriken 

- Lines of Code pro Methode: Maximum sollte unter 20 liegen
- Methoden pro Klasse: sollte zwischen 3 und 15 liegen
- Parameter pro Methode: sollte unter 6 liegen
- Instanzvariablen pro Klasse: Die Zahl sollte unter 10 liegen
- Depth of Inheritance Tree (DIT) = Anzahl der Oberklassen
- Number Of Children (NOC) = Anzahl der direkten Unterklassen
- Weighted Method per Class (WMC) = Anzahl der definierten Methoden
- Coupling Between Object Classes (CBO) = Anzahl der benutzten Klassen
- Lack of Cohesion in Methods (LCOM)
	- Aussage über die “Güte” der Kapselung. Kann Hinweis auf Entwurfsfehler sein.
	- Es gibt unterschiedliche Varianten zur Berechnung von LCOM. Im folgenden werden zwei Varianten dargestellt

### LCOM (Lack of Cohesion in Methods)
LCOM (C) = Methodenpaare ohne gemeinsame Instanzvariablen minus Methodenpaare mit gemeinsamen Instanzvariablen (falls LCOM (C) < 0 => LCOM (C) = 0). Ziel: LCOM (C) = 0

<img src="images/VL15/AnalVerfahren/LCOM.PNG" width=650>
<img src="images/VL15/AnalVerfahren/LCOMBsp.PNG" width=650>

**Lack of Cohesion in Methods (LCOM*) = LCOM-HS (Henderson-Sellers) = LCOM5**
- *LCOM** =  (avgNutzt – m)  /  (1 - m)
	- nutzt(a) die Zahl der Methoden, die eine Instanzvariable a der untersuchten Klasse nutzen 
	- avgNutzt der Durchschnitt aller Werte für alle Instanzvariablen
	- m die Anzahl aller Methoden der untersuchten Klasse



- Ist der Wert nahe Null, handelt es sich um eine eng zusammenhängende Klasse
- Ist der Wert nahe 1, ist die Klasse schwach zusammenhängend und man sollte über eine Aufspaltung nachdenken. Hinweis auf Entwurfsfehler

- Hinweise
	- Es muss vorher festgelegt werden, ob Klassenvariablen und Klassenmethoden berücksichtigt werden sollen
	- Ist LCOM* benutzbar, wenn man auch get()- und set()-Methoden nutzt? 

#### LCOM* Beispiel
			public class C {

				private int a;
				private int b;
				private int c;

	
				public void m1(int x){
					a = a + x;
				}
				public void m2(int x){
					a = a + x;
					b = b - x;
				}
	
				public void m3(int x){
					a = a + x;
					b = b - x;
					c = c + x;
				}
			}
<img src="images/VL15/AnalVerfahren/LCOMBsp2.PNG" width=200>

- LCOM* =  (avgNutzt – m)  /  (1 - m)
	- nutzt(a) die Zahl der Methoden, die eine Instanzvariable a der untersuchten Klasse nutzen 
	- *avgNutzt* der Durchschnitt aller Werte für alle Instanzvariablen
	- m die Anzahl aller Methoden der untersuchten Klasse


## Testende Verfahren

## Testarten im Software Entwicklungsprozess

## Weitere Testarten

## Ermittlung von Testfällen
### Ableitung von Testfällen bei Verwendung von UML
<img src="images/VL15/testUml.png" width="70%" />

### Testfallermittlung
* Auswahl der Testfälle ist eine zentrale Aufgabe des Testens
* Vollständiges Testen in der Regel unmöglich (stichprobenartig testen)
* __Ziel__: Mit möglichst wenig Testfällen möglichst viele Fehler finden

### Verfahren zur Testfallermittlung
<img src="images/VL15/testh.png" width="70%" />

* __Funktionsorientierter__ Test (Black-Box-Test):
    - Testfallauswahl aufgrund der Modulspezifikation Interne Struktur kann unbekannt sein prüft definierte Schnittstellen (Funktionalität)
    - _Datenbezogene Testfälle_:
        - Ausgehend von der Spezifikation des zu untersuchenden Objekts werden verschiedene Eingaben definiert, deren gewünschtes Resultat aus der Spezifikation abzuleiten ist
* __Strukturorientierter__ Test (White-Box-Test)
    - Testfallauswahl aufgrund der internen Struktur prüft die Details der Logik (Codereview)
    - Klassenspezifikation muss ebenfalls bekannt sein (erwartete Resultate)
    - _Ablaufbezogene Testfälle_:
        - Es wird die Struktur des zu untersuchenden Programms analysiert und versucht, möglichst alle Ablaufalternativen (if, while) durchzuspielen

## Funktionsorientierter Test
* Aufdeckung der Abweichung eines Testobjekts von seiner Spezifikation
* Auswahl der Testfälle ohne Kenntnis der inneren Struktur
* Überprüfung des Verhaltens des Testobjekts bei fehlerhaften Eingabedaten
* __Ziel__: Umfassende Prüfung der spezifizierten Funktionalität

__Verfahren zur Testfallermittlung__:
1. Error Guessing
2. Äquivalenzklassenbildung
3. Grenzwertanalyse

### Error Guessing
* Intuitive Auswahl des Testfälle aufgrund von Erfahrung
* Kein systematisches Verfahren
* Ergänzt die Methoden zur Testfallbestimmung

__Typische Fehler__:
* Nichtberücksichtigung von Sonderfällen (z. B. Division durch Null)
* Fehlende Behandlung von Grenzwerten
* Überschreitung von Feldgrenzen
* Endlosschleifen
* Nichtinitialisierung von Variablen
* Falsche logische Operationen (Negationen)

### Äquivalenzklassenbildung
* Gleichartige Eingabedaten werden zu Klassen zusammengefasst und aus jeder Klasse wird ein Repräsentant ausgewählt.
* Bestimmung von gültigen Äquivalenzklassen (Normalfall) sowie ungültigen Äquivalenzklassen (Sonderfall)
* Äquivalenzklassenbildung zerlegt die Menge der Eingaben in disjunkte Teilmengen
* Jeder Repräsentant einer Teilmenge hat das gleiche Verhalten bzgl. einer vorgegebenen Operation
* Beispiel: Restklassen (modulo x): werden zwei beliebige Repräsentanten aus Restklassen addiert, liegt das Ergebnis immer in derselben Restklasse
* Übertragungsidee auf Tests: Eingaben werden in Klassen unterteilt, die durch die Ausführung des zu testenden Systems zu „gleichartigen“ Ergebnissen führen

_Beispiel: Multiplikation zweier ganzer Zahlen:  „void mul(x, y)“_

__Mögliche Äquivalenzklassen__:
* X und Y sind positiv
* X ist positiv und Y ist negativ
* X ist negativ und Y ist positiv
* X und Y sind negativ

#### Regeln zur Bildung von Äquivalenzklassen
* man muss mögliche Eingaben kennen (aus Anforderungs-Spezifikation)
* für einfache Zahlenparameter: Intervall mit gültigen Werten
* Wenn explizit eine Menge von Werten vorgegeben ist: jeder Wert stellt eine Äquivalenzklasse dar

#### Beispiele für Äquivalenzklassen von Eingaben
* Erlaubte Eingabe: 1 <= Wert <= 99 (Wert sei ganzzahlig)
    - eine gültige Äquivalenzklasse: 1 <= Wert <= 99
    - zwei ungültige Äquivalenzklassen: Wert < 1, Wert > 99
* Erlaubte Eingabe in einer Textliste: für ein Auto können zwischen einem und sechs Besitzer eingetragen werden
    - eine gültige Äquivalenzklasse: ein bis sechs Besitzer
    - zwei ungültige Äquivalenzklassen: kein Besitzer, mehr als sechs Besitzer
* Erlaubte Eingabe: Instrumente Klavier, Geige, Orgel, Pauke
    - vier gültige Äquivalenzklassen: Klavier, Geige, Orgel, Pauke
    - eine ungültige Äquivalenzklasse: alles andere, z.B. Zimbeln

#### Beispiel Spezifikation:
* Einem Konstruktor zur Verwaltung von Studierenden wird ein Name, ein Geburtsjahr und ein Fachbereich übergeben.
* Einschränkungen:
    - Das Namensfeld darf nicht leer sein
    - Das Geburtsjahr muss zwischen 1900 und 2000 liegen
    - Es können nur die Fachbereiche aus einer Aufzählung (FBING, FBBWL und FBPOL) übergeben werden

| Eingabe          | gültige Äquivalenzklassen         |  ungültige Äquivalenzklassen   |
| :--------------- |:----------------------------------|:------------------------------ |
| __Name__         | _Ä1)_ nicht leer                  | _Ä2)_ leer                     |
| __Geburtsjahr__  | _Ä4)_ 1900< = Geburtsjahr <= 2000 | _Ä3)_ Geburtsjahr < 1900       |
|                  |                                   | _Ä5)_ Geburtsjahr > 2000       |
| __Fachbereich__  | _Ä6)_ FBING                       |                                |
|                  | _Ä7)_ FBBWL                       |                                |
|                  | _Ä8)_ FBPOL                       |                                |

#### Testfallerzeugung aus Äquivalenzklassen
Die Äquivalenzklassen sind eindeutig zu nummerieren. Für die Erzeugung von Testfällen aus den Äquivalenzklassen sind zwei Regeln zu beachten:
* gültige Äquivalenzklassen:
    - möglichst viele Klassen in einem Test kombinieren
* ungültige Äquivalenzklassen:
    - Auswahl eines (wichtig!) Testdatums aus einer ungültigen Äquivalenzklasse in Kombination mit Werten, die ausschließlich aus gültigen Äquivalenzklassen entnommen sind. Grund: für alle ungültigen Eingabewerte muss eine Fehlerbehandlung existieren

<img src="images/VL15/atable.png" width="70%" />

### Grenzwertanalyse
* Viele Software-Fehler sind auf Schwierigkeiten in Grenzbereichen der Äquivalenzklassen zurück zu führen (z.B. Extremwert nicht berücksichtigt, Array um ein Feld zu klein)
* Aus diesem Grund wird die Untersuchung von Äquivalenzklassen um die Untersuchung der Grenzen ergänzt
* Auswahl von Testfälle für solche Grenzfälle

_Beispiel: 1<=Wert<=99 (ganzzahlig)_
* _Äquivalenzklasse Wert<1:_
    - _obere Grenze Wert=0 (untere Grenze spielt hier keine Rolle)_
* _Äquivalenzklasse Wert>99:_
    - _untere Grenze Wert=100 (obere Grenze spielt keine Rolle)_
* _Äquivalenzklasse 1<=Wert<=99:_
    - _untere Grenze Wert=1 und obere Grenze Wert=99_

_Diese Grenzfallbetrachtung kann direkt in die Testfallerzeugung eingehen_

Testfälle nach einer Äquivalenzklassenanalyse und Grenzwertanalyse
(Testfallanzahl erhöht sich meist)

<img src="images/VL15/gtable.png" width="70%" />

#### Mögliche Übersetzung nach JUnit (Ausschnitt)
```java
import junit.framework.TestCase;

public class ImmatrikulationTest extends TestCase {
    ...

    public void test1(){
        try{
            new Immatrikulation("Meier", 1900, Bereich.FBING);
        }catch(ImmatrikulationsException e){
            fail("falsche Exception");
        }
    }

    public void test4(){
        try{
            new Immatrikulation("", 1988, Bereich.FBING);
            fail("fehlende Exception");
        }catch(ImmatrikulationsException e){
        }
    }

    ...
}

```

## Strukturorientierter Test

## Unittests
1. Die Anzahl der Code-Zeilen für Unittests übersteigt bei weitem die Anzahl der Zeilen des zu testenden Codes.
2. Ein Unittest testet genau eine Klasse.
3. Ein Test ist <strong>kein</strong> Unittest wenn:
  * Er kommuniziert mit einer Datenbank
  * Er kommuniziert mit einem Netzwerk
  * Er kann nicht gleichzeitig mit irgendeinem anderen Unittest ausgeführt werden
  * Es müssen spezille Dinge (wie Änderungen an Konfigurationsdateien) an der Umgebung für die Ausführung getan werden

### Test-Fixture
* Ein Testfall sieht in der Regel so aus, dass eine bestimmte Konfiguration von Objekten aufgebaut wird, gegen die der Test läuft.
* Diese Menge von Testobjekten wird auch als Test-Fixture bezeichnet.
* Damit fehlerhafte Testfälle nicht andere Testfälle beeinflussen können, wird die Test-Fixture für jeden Testfall neu initialisiert.
* In der Methode <strong>setUp</strong> werden Variablen initialisiert und mit der Methode <strong>tearDown</strong> werden wertvolle Testressourcen (z.B. Datenbank- oder Netzwerkverbindungen) wieder freigegeben.

### TestSuite
* Um eine Menge von Tests zusammen ausführen zu können, werden die Tests zu TestSuites zusammengefasst.
* Mit JUnit können beliebig viele Tests in einer TestSuite zusammengefasst werden.
* pro Package eine TestSuite-Klasse definieren.

## TDD (Test-driven delevopment)
<img src="images/VL15/TDD.png" width="100%"/>

### Zusammenspiel von Klassen testen
- Bis jetzt wurde nur eine Klasse betrachtet, die keine Assoziation zu anderen zu testenden Klassen hat
- Weil die Implementierung von andern Klassen noch nicht vorhanden sind, muss man die Implementierung "simulieren", sodass man die eigene Klasse testen kann
- Eine solche Klasse zur "Simulation" wird Test-Double genannnt.
- Liegt die Klasse vor, die man temporär durch den Test-Double prüfen wollte, können diese Tests mit einer realen Klasse wiederholt werden
- Test-Doubles dienen auch für die Implementierung von Klassen, die auf Ressourcen (z. B. Datenbanken) zugreifen, die nicht immer verfügbar sind
- Test-Doubles wurden früher per Hand programmiert. Heutzutage kann man diese per Software automatisch erzeugen lassen:
  * Beispiele: jMoch, http://jmock.org/, EasyMock, http://easymock.org/, Mockito, https://github.com/mockito/mockito
- Achtung:
  * Test-Doubles sind oft aufwändig in der Erstellung, müssen bei Änderungen am Code mit verändert werden und geben keine Garantie dafür, dass die Software keine Fehler enthält. 

## Test Doubles
<img src="images/VL15/TestDoubles.png" width="100%"/>

- Mock: Dynamische und konfigurierbare Laufzeit-Implementierung eines Interfaces oder einer Klasse, für die Rückgabewerte von Methoden definiert werden.
- Stub: Fragmentartige Implementierung als Stellvertreter, genutzt zum Testen.
- Dummy: Ersatzklasse ohne Implementierung als Stellvertreter, um das Testen zu ermöglichen. Wird herumgereicht, aber nicht benutzt. (z.B. um eien Parameterliste einer Methode zu füllen). Muss existieren, aber eine "Interaktion" mit einem Dummy ist nicht angedacht.
- Dummies und Stubs werden erzeugt, um die Testumgebung "lauffähig" zu machen und nicht für die eigentliche "Verifikation" benutzt. Ein Dummy wird als "Wert" herumgereicht, während ein Stub Daten an die zu testende Klasse zurückgibt ("indirekte Inputs").
- Spy: Ein Mock, der die Aufrufe von Methoden etc. zählt
- Spies und Mocks werden benutzt, um die Korrektheit des Kommunikationsablauf zwischen zu testender Klasse und den daran beteiligten Klassen zu überprüfen ("indirekte Outputs").
- Fake: Funktionierende, einfach aufzusetzende, simplifizierte Implementierung mit "gehackter Funktionalität", also nicht verwendbar in Produktion(z.B. eine In-memory-Datenbank). Fakes werden in Integrationstests verwendet.
- Fakes spielen dieselbe Rolle wie Dummies oder Stubs. Sie werden erzeugt, um die Testumgebung lauffähig zu machen, aber nicht für die Verifikation benutzt.
- Test Doubles werden nicht für direkte Outputs der SUT benutzt.
